# Netflix Semantic Recommender -The Maze 

> **Multimodal search & recommender demo for the Netflix catalogue â€“ powered by Sentence-Transformers, BLIP and Gradio.**

Gradio app link [(https://huggingface.co/spaces/karouswissem/the_maze_RS)]

---

## âœ¨ Features

| Input mode | Pipeline                                    | What happens                                                                 |
|------------|---------------------------------------------|------------------------------------------------------------------------------|
| **Text**   | `SentenceTransformer(all-MiniLM-L6-v2)`     | Your query â†’ 384-d embedding â†’ cosine-similarity against precalculated title/overview vectors |
| **Image**  | `BLIP` *base* captioner + ST encoder        | Image â†’ caption â†’ embedding â†’ semantic match                                 |
| **Both**   | Caption âœš text                              | Captions and text concatenated before encoding                               |

* Adjustable **top-N** results (3 / 5 / 10 / 25).  
* Memory-mapped `.npy` keeps RAM usage low even for 100 k+ titles.  
* Runs identical on local Python, Docker and **Hugging Face Spaces** (auto-fetches data with `hf_hub_download`).  

---

## ğŸ“‚ Repository layout

```
.
â”œâ”€ app.py                 â† Gradio interface & API endpoints
â”œâ”€ requirements.txt       â† Locked dependency versions
â”œâ”€ data/                  â† Small example files for local dev
â”‚   â”œâ”€ netflix_embeddings.npy
â”‚   â””â”€ netflix_metadata.csv
â””â”€ assets/
    â””â”€ screenshot.png
```

Large binaries are stored in a separate HF dataset repo: `your-username/netflix-rec-data`.

---

## ğŸš€ Quick start (local)

```bash
# 1. Clone and install deps (Python 3.10+)
python -m pip install -r requirements.txt

# 2. Run the demo
python app.py  # opens http://127.0.0.1:7860
```

If the two data files are missing, the app will download and cache them automatically via `huggingface_hub`.

---

## ğŸ›°ï¸ Deploy on Hugging Face Spaces

1. **Create a new Space â†’ Gradio template**.  
2. Copy everything in this repo except `data/`.  
   (If you keep `data/`, consider Git LFS for the `.npy`.)  
3. In *Settings â†’ Variables & Secrets* add a `HF_TOKEN` **if** the data repo is private.  
4. Push â€“ the Space should build and launch automatically.

```python
# app.py (excerpt)
from huggingface_hub import hf_hub_download

data_repo = "your-username/netflix-rec-data"
emb_path  = hf_hub_download(repo_id=data_repo, filename="netflix_embeddings.npy")
meta_path = hf_hub_download(repo_id=data_repo, filename="netflix_metadata.csv")
```

---

## ğŸ› ï¸ Regenerating embeddings

```python
from sentence_transformers import SentenceTransformer
import pandas as pd, numpy as np

model   = SentenceTransformer("all-MiniLM-L6-v2")
meta_df = pd.read_csv("netflix_titles.csv")
emb     = model.encode(
    meta_df["title"] + ": " + meta_df["description"],
    convert_to_numpy=True,
    show_progress_bar=True
).astype(np.float32)

np.save("netflix_embeddings.npy", emb)
```

Upload both files to the data repo (or replace the ones in `data/`).

---

## ğŸ¤ Contributing

1. Fork âœ branch âœ PR.  
2. Ensure `pre-commit run --all-files` passes (formatting, Ruff, etc.).  
3. For sizeable changes open an issue first to discuss.

---

## ğŸ“„ License

This project is licensed under the **MIT License** â€“ see `LICENSE` for details.

Netflix data Â© Netflix, used here for educational/demo purposes under *fair use*.

---

## ğŸ™ Acknowledgements

* [Sentence-Transformers](https://www.sbert.net/) by UKP TU-Darmstadt & AI2.  
* [BLIP](https://github.com/salesforce/LAVIS) by Salesforce Research.  
* [Gradio](https://gradio.app/) for the lightning-fast demo UI.  
* The open-source community â¤ï¸  
```
